# -*- coding: utf-8 -*-
"""image_classification_cifar10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TU-ltwa3Q8EZ_roMk1NYG2WvCDaAIlIm
"""
# Mount Google Drive 
from google.colab import drive
drive.mount('/content/drive')
#-------------------------------------------------------------------------------

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras import models,layers,losses,utils,callbacks
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import classification_report
import seaborn as sn
#--------------------------------------------------------------------------

# Load CIFAR-10 dataset
(X_train,Y_train),(X_test,Y_test)=tf.keras.datasets.cifar10.load_data()
#---------------------------------------------------------------------------

# Check dimensions of the training and test datasets
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)
#------------------------------------------------------------------------------

# Reshape the target variables to a flat array
Y_train=Y_train.reshape(-1,)
Y_test=Y_test.reshape(-1,)
#--------------------------------------------------------------------------------

# Define class names for CIFAR-10 dataset
classes=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
#------------------------------------------------------------------------------------

# Function to plot a sample image from the dataset
def plot_sample(X,Y,index):
  plt.figure(figsize=(5,1))
  plt.imshow(X[index])
  print(classes[Y[index]])
#------------------------------------------------------------------------------------

# Plot a sample image from the training set
plot_sample(X_train,Y_train,8)
#----------------------------------------------------------------------------------

# Scale pixel values to the range [0, 1]
scaled_X_train=X_train/255
scaled_X_test=X_test/255
#-----------------------------------------------------------------------------------

# One-hot encode the target variables
Y_train_categorical=utils.to_categorical(
    Y_train,num_classes=10
)
Y_test_categorical=utils.to_categorical(
    Y_test,num_classes=10
)
#---------------------------------------------------------------------------------

# Display the first five one-hot encoded labels
Y_train_categorical[:5]
#---------------------------------------------------------------------------------------

# Data augmentation to enhance model robustness
data_aug=tf.keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
])
#-----------------------------------------------------------------------------------

# Function to create and compile the model
def my_model():
  model=models.Sequential([
      data_aug,
      layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(32,32,3)),
      layers.MaxPool2D((2,2)),
      layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'),
      layers.MaxPool2D((2,2)),
      layers.Flatten(),
      layers.Dense(256,activation='relu'),
      layers.Dropout(0.25),
      layers.Dense(128,activation='relu'),
      layers.Dropout(0.25),
      layers.Dense(64,activation='relu'),
      layers.Dropout(0.25),
      layers.Dense(32,activation='relu'),
      layers.Dense(10,activation='sigmoid')
  ])
  model.compile(
      optimizer='adam',
      loss=losses.categorical_crossentropy,
      metrics=['accuracy']
  )
  return model
  

# Function to evaluate the model
def eval(model, X, Y):
    model.evaluate(X, Y)

# Function for making predictions
def prediction(model, X, Y):
    Y_predict = model.predict(X)
    Y_pred = [np.argmax(i) for i in Y_predict]  
    print('Predicted the first five labels:', Y_pred[:5])
    print('True labels of the first five elements:', Y[:5])
    return Y_pred

# Function to display classification report and confusion matrix
def report(truth, predictions):
    print(classification_report(truth, predictions))
    cm = tf.math.confusion_matrix(labels=truth, predictions=predictions)
    plt.figure(figsize=(10, 7))
    sn.heatmap(cm, annot=True, fmt='d')
    plt.xlabel('Predicted')
    plt.ylabel('Truth')

# Function to plot training and validation loss
def plot_loss(history):
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid()
    plt.show()

# Function to plot training and validation accuracy
def plot_accuracy(history):
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid()
    plt.show()
#---------------------------------------------------------------------------------------------

# Create and train the model
model=my_model() # Instantiate the model
tb_callback=callbacks.TensorBoard(log_dir='/logs',histogram_freq=1) # Set up TensorBoard callback
history=model.fit(scaled_X_train,Y_train_categorical,epochs=40,validation_split=0.2,callbacks=tb_callback) # Train the model
#---------------------------------------------------------------------------------------------

# Plot training and validation loss and accuracy
plot_loss(history)
plot_accuracy(history)
#-----------------------------------------------------------------------------------------------

# Evaluate the model on the test set
eval(model,scaled_X_test,Y_test_categorical)
#------------------------------------------------------------------------------------------------

# Make predictions
preds=prediction(model,scaled_X_test,Y_test)
#-------------------------------------------------------------------------------------------------

#Generate a report
report(Y_test,preds)
